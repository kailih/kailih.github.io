{"basics":{"name":"Kaili Huang","label":"Applied Scientist","image":"","email":"kaili@cs.stanford.edu","url":"https://kailihuang.com","summary":"An applied scientist and researcher with a strong background in machine learning and natural language processing.","profiles":[{"network":"LinkedIn","username":"huangkaili","url":"https://www.linkedin.com/in/huangkaili/"}]},"education":[{"institution":"Stanford University","location":"Stanford, California, US","url":"https://www.stanford.edu/","area":"Computer Science (GPA: 4.0/4.0)","studyType":"MS","startDate":"2021-09","endDate":"2023-06","courses":[]},{"institution":"Tsinghua University","location":"Beijing, CHINA","url":"https://www.tsinghua.edu.cn/en/","area":"Industrial Engineering (CS GPA: 3.8/4.0)","studyType":"BE","startDate":"2016-08","endDate":"2020-07","courses":[]}],"work":[{"name":"Microsoft","position":"Applied Scientist","url":"https://www.microsoft.com","startDate":"2023-08-01","endDate":"","summary":"Working in Bing Ads Team.","highlights":["Large language models","Multi-modality","Visual-linguistic","Research"]},{"name":"Microsoft","position":"Data & Applied Scientist Intern","url":"https://www.microsoft.com","startDate":"2022-06-01","endDate":"2022-09-01","summary":"Worked in Bing Ads Team on multi-modality model pruning. Extended Transformer models' structured pruning methods into CLIP (Contrastive Language-Image Pre-training) for the first time. Reduced the model size significantly (-40%) with a slight accuracy drop (-1%).","highlights":["Multi-modality","Model pruning","Transformers","40% model size reduction"]},{"name":"ByteDance","position":"Machine Learning Engineer","url":"https://www.bytedance.com","startDate":"2020-07-01","endDate":"2021-08-01","summary":"Worked on natural language processing (NLP) at Language and Information Technology Group (LITG), AI Lab, supervised by Dr. Hang Li. Constructed a fake news detection pipeline from scratch, and built bot-written articles detection models.","highlights":["Natural language processing","Fake news detection","Bot-written articles detection","AI Lab"]}],"publications":[{"name":"ColBERT-Serve: Efficient Multi-stage Memory-Mapped Scoring","publisher":"Advances in Information Retrieval: 47th European Conference on Information Retrieval, ECIR 2025","releaseDate":"2025-04","url":"https://doi.org/10.1007/978-3-031-88717-8_3","summary":"We study serving retrieval models, particularly late interaction retrievers like ColBERT, to many concurrent users at once and under a small budget, in which the index may not fit in memory. We present ColBERT-serve, a serving system that applies a memory-mapping strategy to the ColBERT index, reducing RAM usage by 90% and permitting its deployment on cheap servers, and incorporates a multi-stage architecture with hybrid scoring, reducing ColBERT's query latency and supporting many concurrent queries in parallel."},{"name":"Overview of the Ninth Dialog System Technology Challenge: DSTC9","publisher":"IEEE/ACM Transactions on Audio, Speech, and Language Processing","releaseDate":"2024-07","url":"https://doi.org/10.1109/TASLP.2024.3426331","summary":"Overview paper for the Ninth Dialog System Technology Challenge (DSTC9), covering multi-domain task-oriented dialogue systems and cross-lingual dialogue state tracking."},{"name":"CrossWOZ: A Large-Scale Chinese Cross-Domain Task-Oriented Dialogue Dataset","publisher":"Transactions of the Association for Computational Linguistics (TACL)","releaseDate":"2020-06","url":"https://aclanthology.org/2020.tacl-1.19","summary":"To advance multi-domain (cross-domain) dialogue modeling as well as alleviate the shortage of Chinese task-oriented datasets, we propose CrossWOZ, the first large-scale Chinese Cross-Domain Wizard-of-Oz task-oriented dataset. It contains 6K dialogue sessions and 102K utterances for 5 domains, including hotel, restaurant, attraction, metro, and taxi."},{"name":"KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation","publisher":"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)","releaseDate":"2020-07","url":"https://www.aclweb.org/anthology/2020.acl-main.635","summary":"We propose a Chinese multi-domain knowledge-driven conversation dataset, KdConv, which grounds the topics in multi-turn conversations to knowledge graphs. Our corpus contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0."},{"name":"A Large-Scale Chinese Short-Text Conversation Dataset","publisher":"Natural Language Processing and Chinese Computing (NLPCC)","releaseDate":"2020-10","url":"https://arxiv.org/abs/2008.03946","summary":"We present a large-scale cleaned Chinese conversation dataset LCCC, which contains a base version (6.8 million dialogues) and a large version (12.0 million dialogues). The quality of our dataset is ensured by a rigorous data cleaning pipeline, which is built based on a set of rules and a classifier that is trained on manually annotated 110K dialogue pairs."},{"name":"Multi-domain Task-oriented Dialog Challenge II at DSTC9","publisher":"AAAI-2021 Dialog System Technology Challenge 9 Workshop","releaseDate":"2021-02","url":"https://www.microsoft.com/en-us/research/publication/multi-domain-task-oriented-dialog-challenge-ii-at-dstc9/","summary":"The paper provides an overview of the 'Multi-Domain Task Completion Dialog Challenge II' track at the 9th Dialog System Technology Challenge (DSTC9). Two tasks are introduced in this track: end-to-end multi-domain task completion and cross-lingual dialog state tracking."}],"projects":[{"name":"Stanford University","position":"Research Assistant","url":"https://www.stanford.edu/","startDate":"2023-01-01","endDate":"2023-06-30","summary":"Collaborated with Prof. Christopher Potts, Prof. Matei Zaharia, and Prof. Kwebena Boahen to explore dendritic computation for advanced knowledge systems. Developed efficient document retrieval systems utilizing innovative memory optimization techniques. Contributed to groundbreaking research at Stanford University, enhancing the understanding of computational models. Published a paper at ECIR 2025.","highlights":["Retrieval","Research"]},{"name":"Stanford University","position":"Research Intern","url":"https://www.stanford.edu/","startDate":"2019-07-01","endDate":"2019-09-30","summary":"As part of the Stanford UGVR program, collaborated with Prof. Tengyu Ma. Applied an innovative algorithmic framework, Stochastic Lower Bound Optimization (SLBO), to building a task-oriented dialogue system for the movie-ticket booking task. Built a Vanilla Policy Gradient (VPG) agent and created a chatbot environment to train the agent. Built a pipeline of taking user simulator samples and training dialogue policies on different model-based deep reinforcement learning (RL) algorithms.","highlights":["Reinforcement learning","Dialogue Systems"]},{"name":"Tsinghua University","position":"Research Assistant","url":"https://www.tsinghua.edu.cn/en/","startDate":"2018-07-01","endDate":"2020-06-30","summary":"Collaborated with Prof. Minlie Huang on advanced research in dialogue systems and natural language generation. Co-authored multiple research papers published in prestigious conferences and journals such as ACL, TACL, and NLPCC. Developed innovative methodologies to enhance machine comprehension, contributing to the field's academic growth.","highlights":["Dialogue Systems","Machine Comprehension","Natural Language Generation"]}],"volunteer":[{"organization":"Conducted 30+ paper review work for top-tier conferences and journals in natural language processing (NLP) and computer vision (CV), including EMNLP'23, ICLR'24, WACV'24, COLING'24, SIGIR'24, KDD‚Äù24, CIKM'24, WACV'25, ICLR'25, COLING'25, ACL'25, Computer Speech & Language.","position":"Reviewer","highlights":"Academic Service","startDate":"2023-01-01"}],"part-time work":[{"name":"Stanford University","position":"Research Assistant","url":"https://www.stanford.edu","startDate":"2023-01-01","endDate":"2023-06-01","summary":"Worked at Stanford Brains in Silicon Lab on dendritic computation for knowledge systems, supervised by Prof. Kwabena Boahen and Prof. Matei Zaharia. Built powerful and efficient document retrieval systems with quantization techniques.","highlights":["Dendritic computation","Knowledge systems","Document retrieval","Quantization techniques"]},{"name":"Stanford University","position":"Research Assistant","url":"https://www.stanford.edu","startDate":"2019-07-01","endDate":"2019-09-01","summary":"Worked on model-based reinforcement learning (RL) for training task-oriented dialogue systems supervised by Prof. Tengyu Ma. Part of Stanford UGVR program ($11,400 sponsorship. Up to 18 students from China are admitted per year).","highlights":["Reinforcement learning","Dialogue systems","UGVR program","$11,400 sponsorship"]},{"name":"Tsinghua University","position":"Research Assistant","url":"https://www.tsinghua.edu.cn","startDate":"2018-07-01","endDate":"2020-06-01","summary":"Worked on dialogue systems, machine comprehension, natural language generation supervised by Prof. Minlie Huang. Published on TACL, ACL, NLPCC, etc.","highlights":["Dialogue systems","Machine comprehension","Natural language generation","TACL","ACL","NLPCC"]},{"name":"Stanford University","position":"Teaching Assistant","url":"https://www.stanford.edu","startDate":"2022-01-01","endDate":"2022-03-01","summary":"Teaching Assistant for CS224N (Natural Language Processing with Deep Learning).","highlights":["CS224N","Natural Language Processing","Deep Learning"]}],"awards":[{"title":"NLPCC Best Student Paper","date":"2020","awarder":"Natural Language Processing and Chinese Computing (NLPCC)","url":"http://tcci.ccf.org.cn/conference/2020/","summary":"NLPCC is a leading international conference specialized in the fields of Natural Language Processing (NLP) and Chinese Computing (CC)."},{"title":"Stanford UGVR Scholar","date":"2019","awarder":"Stanford University, Tsinghua University","url":"https://engineering.stanford.edu/students-academics/global-engineering-programs/undergraduate-visiting-research-program","summary":"Up to 18 students from China are admitted per year"},{"title":"1st Prize in National Olympiad in Informatics in Provinces","date":"2014","awarder":"National Olympiad in Informatics","url":"","summary":"The National Olympiad in Informatics in Provinces (NOIP) is a competitive programming competition for high school students in China. It is one of the most prestigious and challenging competitions in the field of computer science."}],"skills":[{"name":"Computer Science","level":"Master","icon":"fa-solid fa-hashtag","keywords":["Machine Learning","Natural Language Processing","Information Retrieval","Deep Learning","Computer Vision","Multi-modal Models","Large Language Models"]}],"languages":[{"language":"English","fluency":"Fluent","icon":""},{"language":"Chinese","fluency":"Native speaker","icon":""}]}